{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Data From Single Page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create headers to emulate browsing and send GET request to URL\n",
    "\n",
    "headers = {\"User-Agent\":\"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:66.0) Gecko/20100101 Firefox/66.0\", \"Accept-Encoding\":\"gzip, deflate\", \"Accept\":\"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8\", \"DNT\":\"1\",\"Connection\":\"close\", \"Upgrade-Insecure-Requests\":\"1\"}\n",
    "cod_site_data = requests.get('https://callofdutyleague.com/en-us/match/3638', headers=headers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore Content\n",
    "\n",
    "After looking through the returned content, found the site is generated from JSON. The when using Google Inspector, the HTML structure is clear, but this is not what is returned from the request.\n",
    "\n",
    "The data is converted into a string to be split in a manner that isolations the JSON. The json python package is then used to convert the string to json, so the data can be accessed through its key-value structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stores content as bytes-like object\n",
    "cod_site_content = cod_site_data.content\n",
    "\n",
    "# Convert to BeautifulSoup object for parsing then convert to string\n",
    "soup = BeautifulSoup(cod_site_content)\n",
    "string_soup = str(soup)\n",
    "\n",
    "# Split the data at intersections of JSON object\n",
    "string_soup_list = string_soup.split('type=\"application/json\">')\n",
    "string_soup_list_1 = string_soup_list[1].split('</script>')\n",
    "\n",
    "# Load string data into JSON\n",
    "content_dict = json.loads(string_soup_list_1[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse Data from Content\n",
    "\n",
    "Now that the JSON structure is determined, it is possible to extract the data through indexing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Locate wanted data\n",
    "content_dict['props']['pageProps']['blocks'][1]['cdlMatchDetail']['matchData']['matchExtended']['homeTeamCard']\n",
    "\n",
    "# Get Home and Away Team info\n",
    "home_team = content_dict['props']['pageProps']['blocks'][1]['cdlMatchDetail']['matchData']['matchExtended']['homeTeamCard']['name']\n",
    "home_team_id = content_dict['props']['pageProps']['blocks'][1]['cdlMatchDetail']['matchData']['matchExtended']['homeTeamCard']['id']\n",
    "away_team = content_dict['props']['pageProps']['blocks'][1]['cdlMatchDetail']['matchData']['matchExtended']['awayTeamCard']['name']\n",
    "away_team_id = content_dict['props']['pageProps']['blocks'][1]['cdlMatchDetail']['matchData']['matchExtended']['awayTeamCard']['id']\n",
    "\n",
    "# Get total matches won by each team and final result\n",
    "home_team_wins = content_dict['props']['pageProps']['blocks'][1]['cdlMatchDetail']['matchData']['matchExtended']['result']['homeTeamGamesWon']\n",
    "away_team_wins = content_dict['props']['pageProps']['blocks'][1]['cdlMatchDetail']['matchData']['matchExtended']['result']['awayTeamGamesWon']\n",
    "winning_team_id = content_dict['props']['pageProps']['blocks'][1]['cdlMatchDetail']['matchData']['matchExtended']['result']['winnerTeamId']\n",
    "loser_team_id = content_dict['props']['pageProps']['blocks'][1]['cdlMatchDetail']['matchData']['matchExtended']['result']['loserTeamId']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Locate the individual games within each match\n",
    "match_games = content_dict['props']['pageProps']['blocks'][1]['cdlMatchDetail']['matchData']['matchGamesExtended']\n",
    "\n",
    "# Get game-specific data (map, score, mode, etc) and store to list for appending to DataFrame\n",
    "matches = [home_team, home_team_id, away_team, away_team_id, home_team_wins, away_team_wins, winning_team_id, loser_team_id]\n",
    "counter = 0\n",
    "\n",
    "for game in match_games:\n",
    "    counter += 1\n",
    "    print(counter)\n",
    "    match_no = game['matchGame']['number']\n",
    "    match_map = game['matchGame']['map']\n",
    "    mode = game['matchGame']['mode']\n",
    "    locale = game['matchGame']['gameMap']['locale']\n",
    "    try:\n",
    "        home_score = game['matchGameResult']['hostGameScore']\n",
    "        away_score = game['matchGameResult']['guestGameScore']\n",
    "        winning_team = game['matchGameResult']['winnerTeamId']\n",
    "        losing_team = game['matchGameResult']['loserTeamId']\n",
    "    except:\n",
    "        home_score = 0\n",
    "        away_score = 0\n",
    "        winning_team = 0\n",
    "        losing_team = 0\n",
    "        pass\n",
    "    matches.extend([match_no, match_map, mode, locale, home_score, away_score, winning_team, losing_team])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to numpy array for easy transformation\n",
    "matches = np.array(matches)\n",
    "matches = matches.reshape(1, 48)\n",
    "\n",
    "# Convert to DataFrame\n",
    "matches_df = pd.DataFrame(\n",
    "    matches,\n",
    "    columns=['home_team', 'home_team_id', 'away_team', 'away_team_id', 'home_team_wins', 'away_team_wins', 'winning_team_id', 'losing_team_id', 'match_1_id', 'match_1_map', 'match_1_gametype', 'match_1_lang', 'match_1_home_score', 'match_1_away_score', 'match_1_winning_team', 'match_1_losing_team', 'match_2_id', 'match_2_map', 'match_2_gametype', 'match_2_lang', 'match_2_home_score', 'match_2_away_score', 'match_2_winning_team', 'match_2_losing_team', 'match_3_id', 'match_3_map', 'match_3_gametype', 'match_3_lang', 'match_3_home_score', 'match_3_away_score', 'match_3_winning_team', 'match_3_losing_team', 'match_4_id', 'match_4_map', 'match_4_gametype', 'match_4_lang', 'match_4_home_score', 'match_4_away_score', 'match_4_winning_team', 'match_4_losing_team', 'match_5_id', 'match_5_map', 'match_5_gametype', 'match_5_lang', 'match_5_home_score', 'match_5_away_score', 'match_5_winning_team', 'match_5_losing_team']\n",
    ")\n",
    "\n",
    "# Store to CSV for later use\n",
    "matches_df.to_csv('data/2020_reg_season_matches.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get All Match IDs to Programmatically Get Pages\n",
    "\n",
    "This is essentially the same process as above, but for the regular season page to grab each match's page from each series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_sites = requests.get('https://callofdutyleague.com/en-us/schedule?utm_source=cdlweb&utm_medium=navigationbar&utm_campaign=general', headers=headers)\n",
    "all_matches = code_sites.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_soup = BeautifulSoup(all_matches)\n",
    "\n",
    "match_soup_string = str(match_soup)\n",
    "\n",
    "match_soup_list = match_soup_string.split('type=\"application/json\">')\n",
    "match_soup_list_1 = match_soup_list[1].split('</script>')\n",
    "\n",
    "reg_season = json.loads(match_soup_list_1[0])['props']['pageProps']['blocks'][2]['tabs']['tabs'][0]['blocks'][0]['tabs']['tabs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_ids = []\n",
    "\n",
    "for series in reg_season:\n",
    "    final_matches = series['blocks'][2]['tabs']['tabs'][0]['blocks'][0]['cdlMatchCards']['finalMatches']\n",
    "    for match in final_matches:\n",
    "        match_ids.append(match['match']['id'])\n",
    "    print(series['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_df = pd.DataFrame({\n",
    "    'ids': match_ids\n",
    "})\n",
    "\n",
    "ids_df.to_csv('data/2020_reg_season_match_ids.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = pd.read_csv('data/2020_reg_season_match_ids.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = list(ids['ids'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Turn it all into Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_page_data(_id):\n",
    "    \"\"\"\n",
    "    Trigger request to get url with appended match id. Converts \n",
    "    it from bytes type to final JSON object.\n",
    "    \n",
    "    INPUT: Integer id of match.\n",
    "    \n",
    "    OUTPUT: JSON object of page data.\n",
    "    \"\"\"\n",
    "    data = requests.get()\n",
    "    # Stores content as bytes-like object\n",
    "    content = data.content\n",
    "\n",
    "    # Convert to BeautifulSoup object for parsing then convert to string\n",
    "    soup = BeautifulSoup(content)\n",
    "    string_soup = str(soup)\n",
    "\n",
    "    # Split the data at intersections of JSON object\n",
    "    string_soup_list = string_soup.split('type=\"application/json\">')\n",
    "    string_soup_list_1 = string_soup_list[1].split('</script>')\n",
    "\n",
    "    # Load string data into JSON\n",
    "    content_dict = json.loads(string_soup_list_1[0])\n",
    "\n",
    "    page_data.append(content_dict)\n",
    "    return page_data\n",
    "\n",
    "def parse_page_data(data):\n",
    "    \"\"\"\n",
    "    Parse through page data to collect desired data points.\n",
    "    \n",
    "    INPUT: JSON object of page data.\n",
    "    \n",
    "    OUTPUT: List of data points from page.\n",
    "    \"\"\"\n",
    "    # Locate wanted data\n",
    "    content_dict['props']['pageProps']['blocks'][1]['cdlMatchDetail']['matchData']['matchExtended']['homeTeamCard']\n",
    "\n",
    "    # Get Home and Away Team info\n",
    "    home_team = content_dict['props']['pageProps']['blocks'][1]['cdlMatchDetail']['matchData']['matchExtended']['homeTeamCard']['name']\n",
    "    home_team_id = content_dict['props']['pageProps']['blocks'][1]['cdlMatchDetail']['matchData']['matchExtended']['homeTeamCard']['id']\n",
    "    away_team = content_dict['props']['pageProps']['blocks'][1]['cdlMatchDetail']['matchData']['matchExtended']['awayTeamCard']['name']\n",
    "    away_team_id = content_dict['props']['pageProps']['blocks'][1]['cdlMatchDetail']['matchData']['matchExtended']['awayTeamCard']['id']\n",
    "\n",
    "    # Get total matches won by each team and final result\n",
    "    home_team_wins = content_dict['props']['pageProps']['blocks'][1]['cdlMatchDetail']['matchData']['matchExtended']['result']['homeTeamGamesWon']\n",
    "    away_team_wins = content_dict['props']['pageProps']['blocks'][1]['cdlMatchDetail']['matchData']['matchExtended']['result']['awayTeamGamesWon']\n",
    "    winning_team_id = content_dict['props']['pageProps']['blocks'][1]['cdlMatchDetail']['matchData']['matchExtended']['result']['winnerTeamId']\n",
    "    loser_team_id = content_dict['props']['pageProps']['blocks'][1]['cdlMatchDetail']['matchData']['matchExtended']['result']['loserTeamId']\n",
    "\n",
    "    # Locate the individual games within each match\n",
    "    match_games = content_dict['props']['pageProps']['blocks'][1]['cdlMatchDetail']['matchData']['matchGamesExtended']\n",
    "\n",
    "    # Get game-specific data (map, score, mode, etc) and store to list for appending to DataFrame\n",
    "    matches = [home_team, home_team_id, away_team, away_team_id, home_team_wins, away_team_wins, winning_team_id, loser_team_id]\n",
    "    counter = 0\n",
    "    \n",
    "    # Iterate through each game in each match\n",
    "    for game in match_games:\n",
    "        counter += 1\n",
    "        print(counter)\n",
    "        match_no = game['matchGame']['number']\n",
    "        match_map = game['matchGame']['map']\n",
    "        mode = game['matchGame']['mode']\n",
    "        locale = game['matchGame']['gameMap']['locale']\n",
    "        try:\n",
    "            home_score = game['matchGameResult']['hostGameScore']\n",
    "            away_score = game['matchGameResult']['guestGameScore']\n",
    "            winning_team = game['matchGameResult']['winnerTeamId']\n",
    "            losing_team = game['matchGameResult']['loserTeamId']\n",
    "        except:\n",
    "            home_score = 0\n",
    "            away_score = 0\n",
    "            winning_team = 0\n",
    "            losing_team = 0\n",
    "            pass\n",
    "        matches.extend([match_no, match_map, mode, locale, home_score, away_score, winning_team, losing_team])\n",
    "    return matches\n",
    "        \n",
    "\n",
    "def store_match_data(df, match):\n",
    "    \"\"\"\n",
    "    Append list of data points to Pandas DataFrame of previous match data.\n",
    "    \n",
    "    INPUT: Pandas DataFrame of data. \n",
    "    \n",
    "    OUTPUT: List of data points from page.\n",
    "    \"\"\"\n",
    "    to_append = match\n",
    "    df_length = len(df)\n",
    "    df.loc[df_length] = to_append\n",
    "    return df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
